{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c4345867-6ce7-4f35-825c-80aef9048251",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Logistic Regression Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "19f1bb39-ff7f-493e-a264-6bda9e00aeb0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# this allows pyspark.ml for accelerated estimators to import the accelerated versions\n",
    "# comment out or skip for CPU only runs\n",
    "import spark_rapids_ml.install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a7c21330-7326-4d98-9351-d1b2e4c6143c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from gen_data_distributed import ClassificationDataGen, SparseRegressionDataGen\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator, MulticlassClassificationEvaluator\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "94260ecc-3b2e-42ef-ac47-18ecfd330883",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Disable mlflow auto logging as it is resource intensive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "58cea259-8b15-4f0c-b0ed-4787999ab380",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import mlflow\n",
    "mlflow.autolog(disable=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7441ded7-4473-4981-9ff0-85bf2835a970",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Create synthetic dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9d358681-da1c-4415-abed-ff8afbd7e444",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "The number of classes in the dataset is set to 2 below.  Larger values for `n_classes` are also supported."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e658f6ae-b697-446e-86e6-6820d292d5f8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "n_classes = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "291da378-0e9b-4b53-bf9e-b78c35631f1d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Passing {'n_redundant': 1, 'random_state': 1} to make_classification\n"
     ]
    }
   ],
   "source": [
    "#n_rows = 20000000000\n",
    "n_rows = 20000000000\n",
    "n_cols = 3\n",
    "n_files = 2000\n",
    "output = f\"s3://eordentlich/polynomial-lr/{int(n_rows/1e9)}bx{n_cols}\"\n",
    "data_generator = ClassificationDataGen(argv=[\"--no_shutdown\", \"--num_rows\", f\"{n_rows}\", \"--num_cols\", f\"{n_cols}\", \n",
    "                                             \"--output_num_files\", f\"{n_files}\", \"--output_dir\", output, \"--n_redundant\", \"1\"])\n",
    "\n",
    "generated_df = data_generator.gen_dataframe(spark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9cc5d0f0-acbc-4b99-8e43-aef24ffc8de7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "n_rows = 20000000000\n",
    "n_cols = 300\n",
    "n_files = 2000\n",
    "output = f\"s3://eordentlich/polynomial-lr/{int(n_rows/1e9)}bx{n_cols}_sparse\"\n",
    "data_generator = SparseRegressionDataGen(argv=[\"--no_shutdown\", \"--num_rows\", f\"{n_rows}\", \"--num_cols\", f\"{n_cols}\", \n",
    "                                             \"--output_num_files\", f\"{n_files}\", \"--output_dir\", output, \"--n_redundant\", \"1\",\n",
    "                                             \"--density_curve\", \"Linear\",\n",
    "                                             ])\n",
    "\n",
    "generated_df = data_generator.gen_dataframe(spark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6c80a79e-0d9f-4ff1-81b6-9d39d8677fc8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "2000"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generated_df[0].rdd.getNumPartitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5cc1c907-83d2-4ba8-8094-70eb9517f07d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "generated_df[0].write.parquet(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "184d7eea-fbdc-40e6-b0d9-713489b789f9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'s3://eordentlich/polynomial-lr/10bx4'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5d1a10f9-a9d9-452f-bcd2-b3d8a4b2f0ce",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f21e3ba6-f4d4-4a71-b9a1-187c3b83f261",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "1250000000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = spark.read.parquet('s3://eordentlich/polynomial-lr/10bx4/part-00{0,1}*','s3://eordentlich/polynomial-lr/10bx4/part-002{0,1,2,3,4}*')\n",
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7933e15e-031c-4ee7-ba5c-38ddd206749b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "DataFrame[c0: float, c1: float, c2: float, c3: float, label: float]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6a184605-74aa-449a-b5d0-c825f296c0a9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['c0', 'c1', 'c2', 'c3']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_cols=df.columns\n",
    "feature_cols.remove(\"label\")\n",
    "feature_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ca8df053-6ea6-440a-83a0-cd16ead498f4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.feature import PolynomialExpansion\n",
    "\n",
    "# this is a transform only pipeline so not dataprocessing is actually run\n",
    "pipeline = Pipeline(stages=[\n",
    "    VectorAssembler(inputCols=feature_cols, outputCol=\"features\"),\n",
    "    PolynomialExpansion(inputCol=\"features\", outputCol=\"expanded_features\", degree=2),\n",
    "]).fit(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8102ccdb-bba3-4f43-a622-eeeface260b5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# keep only expanded features for training\n",
    "train_df = pipeline.transform(df).drop(*(feature_cols + [\"features\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "abf36a01-d4ed-4c52-b691-9bac5eae0545",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "DataFrame[label: float, expanded_features: vector]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d5fe62df-cbd3-4173-ba74-c5c4ce7104a1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[Row(label=0.0, features=DenseVector([-2.2766, 5.1828, -3.0791, 7.0099, 9.481, 0.242, -0.551, -0.7453, 0.0586, -0.4621, 1.052, 1.4228, -0.1118, 0.2135])),\n",
       " Row(label=0.0, features=DenseVector([-0.7339, 0.5386, 0.7457, -0.5472, 0.556, -0.2095, 0.1537, -0.1562, 0.0439, 0.7099, -0.521, 0.5293, -0.1487, 0.5039])),\n",
       " Row(label=0.0, features=DenseVector([-1.4893, 2.218, -1.4956, 2.2274, 2.2369, 0.0726, -0.1081, -0.1085, 0.0053, 0.8614, -1.2829, -1.2883, 0.0625, 0.742])),\n",
       " Row(label=1.0, features=DenseVector([0.7798, 0.6081, -1.1091, -0.8648, 1.23, 0.275, 0.2144, -0.3049, 0.0756, 0.6444, 0.5025, -0.7146, 0.1772, 0.4152])),\n",
       " Row(label=1.0, features=DenseVector([0.8752, 0.766, 1.8113, 1.5852, 3.2807, -0.1968, -0.1723, -0.3565, 0.0387, -0.8866, -0.7759, -1.6058, 0.1745, 0.786]))]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df=train_df.withColumnRenamed(\"expanded_features\", \"features\")\n",
    "train_df.take(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "90b36ddc-2f90-409b-a213-3f319c736134",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Train with CrossValidator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0e123b05-661f-4e22-ba93-01bb13e0292a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def build_lr_classifier(estimator_class):\n",
    "    return ( estimator_class(verbose=7)\n",
    "                .setFeaturesCol(\"features\")\n",
    "                .setLabelCol(\"label\")\n",
    "                .setRegParam(0.001)\n",
    "                .setElasticNetParam(0.5)\n",
    "                .setMaxIter(100)\n",
    "                .setTol(1.0e-30)\n",
    "           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "027faa6b-16e8-493e-a7df-0b3440608540",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def build_lr_classifier(estimator_class):\n",
    "    return ( estimator_class()\n",
    "                .setFeaturesCol(\"features\")\n",
    "                .setLabelCol(\"label\")\n",
    "                .setRegParam(0.001)\n",
    "                .setElasticNetParam(0.5)\n",
    "                .setMaxIter(100)\n",
    "                .setTol(1.0e-30)\n",
    "           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "559be116-df65-4d64-b549-6f1e5f813b08",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LogisticRegression\n",
    "classifier = build_lr_classifier(LogisticRegression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d6a595d8-f549-4d3d-b424-fe3a2eaeb9be",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "spark_rapids_ml.classification.LogisticRegression"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a1bbbc51-79da-460d-b16a-be646f30fc57",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:spark_rapids_ml.classification.LogisticRegression:CUDA managed memory enabled.\nINFO:spark_rapids_ml.classification.LogisticRegression:Training tasks require the resource(cores=16, gpu=1.0)\nINFO:spark_rapids_ml.classification.LogisticRegression:Training spark-rapids-ml with 4 worker(s) ...\nINFO:spark_rapids_ml.classification.LogisticRegression:Finished training\n"
     ]
    }
   ],
   "source": [
    "model=classifier.fit(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3168f24c-ec58-4a8b-bf61-d782e774b662",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# gpu accelerated crossvalidation does not yet support AUC (and similar) - will fall back to suboptimal processing, so use logLoss, which is supported.\n",
    "eval = MulticlassClassificationEvaluator(metricName=\"logLoss\", labelCol=\"label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "561366be-271d-4889-8ba1-c489858cc770",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def with_benchmark(phrase, action):\n",
    "    start = time.time()\n",
    "    result = action()\n",
    "    end = time.time()\n",
    "    print(\"{} takes {} seconds\".format(phrase, end - start))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6a24e1f8-d2c2-4f5d-bd22-40f071b27fa7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "grid = (\n",
    "        ParamGridBuilder().addGrid(classifier.regParam, [0.00005, 0.001, 0.005, 0.01])\n",
    "                            .addGrid(classifier.elasticNetParam, [0.25, 0.5, 0.75, 0.9])\n",
    "                            .build()\n",
    "    )\n",
    "\n",
    "cv = CrossValidator(estimator=classifier, estimatorParamMaps=grid, evaluator=eval, parallelism=1, seed=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e6f71bc0-b788-476d-8f30-ac58043d4c24",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "spark_rapids_ml.tuning.CrossValidator"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "type(cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f53b9bf0-3e13-4761-a910-5d2b6ae4078b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:spark_rapids_ml.classification.LogisticRegression:CUDA managed memory enabled.\nINFO:spark_rapids_ml.classification.LogisticRegression:Training tasks require the resource(cores=16, gpu=1.0)\nINFO:spark_rapids_ml.classification.LogisticRegression:Training spark-rapids-ml with 4 worker(s) ...\nINFO:spark_rapids_ml.classification.LogisticRegression:Finished training\nINFO:spark_rapids_ml.classification.LogisticRegressionModel:CUDA managed memory enabled.\nINFO:spark_rapids_ml.classification.LogisticRegression:CUDA managed memory enabled.\nINFO:spark_rapids_ml.classification.LogisticRegression:Training tasks require the resource(cores=16, gpu=1.0)\nINFO:spark_rapids_ml.classification.LogisticRegression:Training spark-rapids-ml with 4 worker(s) ...\nINFO:spark_rapids_ml.classification.LogisticRegression:Finished training\nINFO:spark_rapids_ml.classification.LogisticRegressionModel:CUDA managed memory enabled.\nINFO:spark_rapids_ml.classification.LogisticRegression:CUDA managed memory enabled.\nINFO:spark_rapids_ml.classification.LogisticRegression:Training tasks require the resource(cores=16, gpu=1.0)\nINFO:spark_rapids_ml.classification.LogisticRegression:Training spark-rapids-ml with 4 worker(s) ...\nINFO:spark_rapids_ml.classification.LogisticRegression:Finished training\nINFO:spark_rapids_ml.classification.LogisticRegressionModel:CUDA managed memory enabled.\nINFO:spark_rapids_ml.classification.LogisticRegression:CUDA managed memory enabled.\nINFO:spark_rapids_ml.classification.LogisticRegression:Training tasks require the resource(cores=16, gpu=1.0)\nINFO:spark_rapids_ml.classification.LogisticRegression:Training spark-rapids-ml with 4 worker(s) ...\nINFO:spark_rapids_ml.classification.LogisticRegression:Finished training\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training CV takes 3468.310155391693 seconds\naverage metrics: [0.0874251412252141, 0.08742422382011435, 0.08742667654949954, 0.08742304175880637, 0.08935976529076677, 0.08886029039149217, 0.08839960716405448, 0.08812804930149491, 0.10306701046433374, 0.10057026574495233, 0.09723698525041587, 0.0943568591232843, 0.11900523566389483, 0.11523139049544802, 0.10892823571240758, 0.10383245881082369]\n"
     ]
    }
   ],
   "source": [
    "# gpu 16 param sweeps, 4x g5.4xlarge\n",
    "model = with_benchmark(\"Training CV\", lambda: cv.fit(train_df))\n",
    "print(f\"average metrics: {model.avgMetrics}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8c2c86a7-f42e-40a4-bf30-916196d60c25",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# 40x g5.2xlarge\n",
    "model = with_benchmark(\"Training CV\", lambda: cv.fit(train_df))\n",
    "print(f\"average metrics: {model.avgMetrics}\")\n",
    "\n",
    "# INFO:spark_rapids_ml.classification.LogisticRegression:CUDA managed memory enabled.\n",
    "# INFO:spark_rapids_ml.classification.LogisticRegression:Training tasks require the resource(cores=8, gpu=1.0)\n",
    "# INFO:spark_rapids_ml.classification.LogisticRegression:Training spark-rapids-ml with 40 worker(s) ...\n",
    "# INFO:spark_rapids_ml.classification.LogisticRegression:Finished training\n",
    "# INFO:spark_rapids_ml.classification.LogisticRegressionModel:CUDA managed memory enabled.\n",
    "# INFO:spark_rapids_ml.classification.LogisticRegression:CUDA managed memory enabled.\n",
    "# INFO:spark_rapids_ml.classification.LogisticRegression:Training tasks require the resource(cores=8, gpu=1.0)\n",
    "# INFO:spark_rapids_ml.classification.LogisticRegression:Training spark-rapids-ml with 40 worker(s) ...\n",
    "# INFO:spark_rapids_ml.classification.LogisticRegression:Finished training\n",
    "# INFO:spark_rapids_ml.classification.LogisticRegressionModel:CUDA managed memory enabled.\n",
    "# INFO:spark_rapids_ml.classification.LogisticRegression:CUDA managed memory enabled.\n",
    "# INFO:spark_rapids_ml.classification.LogisticRegression:Training tasks require the resource(cores=8, gpu=1.0)\n",
    "# INFO:spark_rapids_ml.classification.LogisticRegression:Training spark-rapids-ml with 40 worker(s) ...\n",
    "# INFO:spark_rapids_ml.classification.LogisticRegression:Finished training\n",
    "# INFO:spark_rapids_ml.classification.LogisticRegressionModel:CUDA managed memory enabled.\n",
    "# INFO:spark_rapids_ml.classification.LogisticRegression:CUDA managed memory enabled.\n",
    "# INFO:spark_rapids_ml.classification.LogisticRegression:Training tasks require the resource(cores=8, gpu=1.0)\n",
    "# INFO:spark_rapids_ml.classification.LogisticRegression:Training spark-rapids-ml with 40 worker(s) ...\n",
    "# INFO:spark_rapids_ml.classification.LogisticRegression:Finished training\n",
    "# Training CV takes 2047.1421689987183 seconds\n",
    "# average metrics: [0.2756548008318942, 0.2784477526711268, 0.6326207601499868, 0.693147183212503]"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "logistic-regression-gpu",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  },
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}